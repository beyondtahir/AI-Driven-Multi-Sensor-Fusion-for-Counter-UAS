Drones have become the weapon of choice in asymmetric conflicts. Their affordability, availability, and stealth capabilities challenge traditional air defense systems. Countries like Pakistan, positioned at the nexus of regional conflict, cannot afford brittle detection pipelines. The cost curves are striking: defending against a $1,000 drone with a $2 million missile is unsustainable. This asymmetry calls for AI-enabled early detection systems that prioritize accuracy, speed, and cost-efficiency.

While radar, EO/IR, RF, and acoustic sensors have individually shown promise, each modality has limitations under clutter, weather, or deliberate jamming. Fusion—integrating multiple modalities—has emerged as a critical path forward. Yet most existing literature and defense systems still rely on rule-based or isolated modality pipelines, leaving a gap for scalable AI-driven solutions.

Our contributions are threefold: (1) we design a robust multi-sensor fusion architecture tailored for C-UAS in contested environments, (2) we establish new evaluation metrics aligned with defense realities, and (3) we contextualize this framework for Pakistan, offering a model adaptable to similar developing defense ecosystems.
